{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Speaker_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritikraj660/Speaker-recognition/blob/master/Speaker_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpNLfJBO1-WH",
        "colab_type": "text"
      },
      "source": [
        "# Installing Packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj01p9v5K199",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjuL4ZnF2F_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RXw9shFmGBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "5c8cca91-853e-47a0-fe31-927df39596a4"
      },
      "source": [
        "!pip install soundfile\n",
        "!pip install spafe"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n",
            "Collecting spafe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/72/9a25cb3f117e1751c66e1f3368d9a787f7ad2c226078b884b6d218a4c5eb/spafe-0.1.1-py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from spafe) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.6/dist-packages (from spafe) (1.17.5)\n",
            "Installing collected packages: spafe\n",
            "Successfully installed spafe-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhg7V0a2H9L",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jYJat4GEpzL",
        "colab_type": "code",
        "outputId": "0146bee3-e88b-40a3-9214-4a0c66bb0566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import tqdm\n",
        "from scipy.io import wavfile\n",
        "import glob\n",
        "import os,pickle\n",
        "import numpy as np\n",
        "from spafe.features.mfcc import mfcc, imfcc\n",
        "import csv\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import model_from_json\n",
        "from keras import backend as K"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0XYclYb2NlS",
        "colab_type": "text"
      },
      "source": [
        "# Import Data from Drive :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7LFfT5dOyO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulBEeHGOPVb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFtoL6s2PVFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c5176f0-0164-46e1-c7d1-7f2eb98de518"
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1-jhCnWc1Pg5PKjY1aME8JwsVHXljmjFF'\n",
        "fluff, id = link.split('=')\n",
        "print (id) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-jhCnWc1Pg5PKjY1aME8JwsVHXljmjFF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpzvACTgPyj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('LibriSpeech.rar')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCRUyoks2WwX",
        "colab_type": "text"
      },
      "source": [
        "# Extracting Data from (.)rar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUsfP_J5PySI",
        "colab_type": "code",
        "outputId": "b16511b0-5b42-4d4e-c850-e0bdedad5a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip install patool"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffyDpxaCSgDx",
        "colab_type": "code",
        "outputId": "988e7d83-edf1-4b1d-a9c3-bf64d5105bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'adc.json', 'LibriSpeech', 'LibriSpeech.rar', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH0Ug5BPShB8",
        "colab_type": "code",
        "outputId": "8c19c7a8-b619-4d84-9c07-480c8ccf131d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"LibriSpeech.rar\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting LibriSpeech.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/LibriSpeech.rar\n",
            "patool:     with cwd='./Unpack_1olhabgk'\n",
            "patool: ... LibriSpeech.rar extracted to `LibriSpeech'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LibriSpeech'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcQzszcy2htw",
        "colab_type": "text"
      },
      "source": [
        "# Audio Data Preprocessing :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73C5dhr-me2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_(x,mean = False):\n",
        "    if mean == True:\n",
        "        return (x - np.mean(x)) / (np.max(x) - np.min(x)) #normalization                             \n",
        "    else:\n",
        "        return (x-np.mean(x)/np.std(x)) #standardization\n",
        "\n",
        "def zero_handling(x):\n",
        "    \"\"\"\n",
        "    handle the issue with zero values if they are exposed to become an argument\n",
        "    for any log function.\n",
        "\n",
        "    Returns:\n",
        "        vector with zeros substituted with epsilon values.\n",
        "    \"\"\"\n",
        "    return np.where(x == float(0), np.finfo(float).eps, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSPPghULme23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mfcc_(sig,fs):\n",
        "    mfccs  = mfcc(sig, fs=fs, num_ceps=20, pre_emph=1, pre_emph_coeff=0.95, \n",
        "              win_len=0.025, win_hop=0.01, win_type='hamming', nfilts=26, \n",
        "              nfft=512, low_freq=None, high_freq=None, scale='constant', \n",
        "              dct_type=2, use_energy=False, lifter=22)\n",
        "    #print(fs)\n",
        "    return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaE6275lme26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label(user,total): # its creating lable for splited audio data\n",
        "    k_train = []\n",
        "    for i in range(total):\n",
        "        k_train.append(user)\n",
        "    y_train=np.array(k_train).T\n",
        "    return y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5hyRZYb0njc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "#for file_path in Path('LibriSpeech/test-clean').glob('**/*.flac'):\n",
        "#     print(file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV0iqD15me3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def s2c(mfcc=False,lpcc=False):\n",
        "    x,y=[],[]\n",
        "    data = np.empty([1,148,20])\n",
        "    data_label = np.asarray([])\n",
        "    count =0  # E:\\dataset\\LibriSpeech\\dev-clean\n",
        "    #for file in tqdm(glob.iglob('/LibriSpeech/test-clean//**/*.flac', recursive=True)):\n",
        "    for file in tqdm(Path('LibriSpeech/test-clean').glob('**/*.flac')):\n",
        "        file_name=os.path.basename(file)\n",
        "        user = file_name.split(\"-\")[0]\n",
        "        #print(f)\n",
        "        with soundfile.SoundFile(file) as sound_file:\n",
        "                signal = sound_file.read(dtype=\"float32\")\n",
        "                sr=sound_file.samplerate\n",
        "        signal = norm_(signal,mean = False)\n",
        "        signal = zero_handling(signal)\n",
        "        \n",
        "        if mfcc:\n",
        "            feature = mfcc_(signal,sr)\n",
        "            #print(feature.shape[0])\n",
        "        if lpcc:\n",
        "            feature = lpcc_(signal,sr)   \n",
        "        #if feature.shape[0]>256:\n",
        "        \n",
        "        quotient = int(feature.shape[0]/148)\n",
        "        end_index = feature.shape[0]-(feature.shape[0]%148)\n",
        "        r = feature[0:end_index,:]\n",
        "        re_data = np.reshape(r,(-1,148,20))#b = np.reshape(a, (8, 3, -1))\n",
        "        data=np.concatenate((data,re_data),axis=0)\n",
        "        \n",
        "        re_label = label(user,quotient)\n",
        "        data_label = np.concatenate((data_label,re_label),axis=0)\n",
        "    return data[1:,:,:],data_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atS_es2Ame3Z",
        "colab_type": "code",
        "outputId": "75612f41-a762-48d9-d17b-f7a3e871c5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "def write_(x,y):\n",
        "    with open('mfcc_data.csv', 'a') as mfcc_dataFile:\n",
        "        writer = csv.writer(mfcc_dataFile)\n",
        "        writer.writerows(x)\n",
        "    mfcc_dataFile.close()\n",
        "    with open('mfcc_label.csv', 'a') as mfcc_labelFile:\n",
        "        writer = csv.writer(mfcc_labelFile)\n",
        "        writer.writerows(y)\n",
        "    mfcc_labelFile.close()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14 µs, sys: 6 µs, total: 20 µs\n",
            "Wall time: 22.9 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAmw3NFOEp8p",
        "colab_type": "code",
        "outputId": "e2326883-f47f-4f30-ef3a-a1a49517f75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "%%time\n",
        "x,y = s2c(mfcc=True,lpcc=False)\n",
        "\n",
        "#write_(x,y)\n",
        "print(x.shape,y.shape)\n",
        "\n",
        "\n",
        "u = np.unique(y)\n",
        "num_classes = len(u)\n",
        "#print(u)\n",
        "d = dict()\n",
        "for enu,key in enumerate(u,0):\n",
        "    d[key]=enu\n",
        "print(d)\n",
        "for i in range(len(y)):\n",
        "    y[i] = d[y[i]]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2620it [03:02,  7.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11806, 148, 20) (11806,)\n",
            "{'1089': 0, '1188': 1, '121': 2, '1221': 3, '1284': 4, '1320': 5, '1580': 6, '1995': 7, '2094': 8, '2300': 9, '237': 10, '260': 11, '2830': 12, '2961': 13, '3570': 14, '3575': 15, '3729': 16, '4077': 17, '4446': 18, '4507': 19, '4970': 20, '4992': 21, '5105': 22, '5142': 23, '5639': 24, '5683': 25, '61': 26, '672': 27, '6829': 28, '6930': 29, '7021': 30, '7127': 31, '7176': 32, '7729': 33, '8224': 34, '8230': 35, '8455': 36, '8463': 37, '8555': 38, '908': 39}\n",
            "CPU times: user 3min 20s, sys: 2min 33s, total: 5min 53s\n",
            "Wall time: 3min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbqqVr_6Ep9d",
        "colab_type": "code",
        "outputId": "4dfcb21e-0587-4dd5-dc7f-7d825c299ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "X  = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "y_binary = keras.utils.to_categorical(y, num_classes = num_classes)\n",
        "print(y_binary.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y_binary ,test_size=0.20, shuffle= True)\n",
        "\n",
        "print(\"Training shape: {0}, Training label shape : {1}\".format(x_train.shape,y_train.shape))\n",
        "print(\"Training shape: {0}, Training label shape : {1}\".format(x_test.shape,y_test.shape))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11806, 148, 20, 1)\n",
            "(11806, 40)\n",
            "Training shape: (9444, 148, 20, 1), Training label shape : (9444, 40)\n",
            "Training shape: (2362, 148, 20, 1), Training label shape : (2362, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1HwaUks6gKY",
        "colab_type": "text"
      },
      "source": [
        "# Creating CNN Architecture :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6w-KrxMEp-O",
        "colab_type": "code",
        "outputId": "4f19258e-583b-432d-a897-8c4809eaeea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.python.keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model2 = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x.shape[1],x.shape[2],1)))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(40, activation='softmax'))\n",
        "\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model2.summary())#Train and Test The Model\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 146, 18, 32)       320       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 144, 16, 32)       9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 70, 6, 64)         18496     \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 68, 4, 64)         36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               1114368   \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 40)                10280     \n",
            "=================================================================\n",
            "Total params: 1,189,640\n",
            "Trainable params: 1,189,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C4e0DA7Ep_K",
        "colab_type": "code",
        "outputId": "7276a023-62fa-44ac-a836-25ec20b789ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "%%time\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# Saving the model that performed the best on the validation set\n",
        "checkpoint = ModelCheckpoint(filepath='Model.v_1.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "# Training the model for 40 epochs\n",
        "history = model2.fit(x_train, y_train, batch_size=16, epochs=100, \n",
        "                    validation_data=(x_test, y_test), verbose=1, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9444 samples, validate on 2362 samples\n",
            "Epoch 1/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.7875 - accuracy: 0.4521\n",
            "Epoch 00001: val_loss improved from inf to 1.44645, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.7875 - accuracy: 0.4521 - val_loss: 1.4464 - val_accuracy: 0.5732\n",
            "Epoch 2/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.6497 - accuracy: 0.4952\n",
            "Epoch 00002: val_loss improved from 1.44645 to 1.30000, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.6498 - accuracy: 0.4951 - val_loss: 1.3000 - val_accuracy: 0.6279\n",
            "Epoch 3/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.5361 - accuracy: 0.5322\n",
            "Epoch 00003: val_loss improved from 1.30000 to 1.21630, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.5359 - accuracy: 0.5323 - val_loss: 1.2163 - val_accuracy: 0.6304\n",
            "Epoch 4/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.4276 - accuracy: 0.5568\n",
            "Epoch 00004: val_loss improved from 1.21630 to 1.13653, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.4276 - accuracy: 0.5568 - val_loss: 1.1365 - val_accuracy: 0.6647\n",
            "Epoch 5/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.3193 - accuracy: 0.5865\n",
            "Epoch 00005: val_loss improved from 1.13653 to 1.09472, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.3191 - accuracy: 0.5865 - val_loss: 1.0947 - val_accuracy: 0.6732\n",
            "Epoch 6/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.2735 - accuracy: 0.6076\n",
            "Epoch 00006: val_loss improved from 1.09472 to 1.02738, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 85s 9ms/sample - loss: 1.2734 - accuracy: 0.6077 - val_loss: 1.0274 - val_accuracy: 0.6914\n",
            "Epoch 7/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.1992 - accuracy: 0.6220\n",
            "Epoch 00007: val_loss did not improve from 1.02738\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.1991 - accuracy: 0.6221 - val_loss: 1.0661 - val_accuracy: 0.6660\n",
            "Epoch 8/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.1605 - accuracy: 0.6404\n",
            "Epoch 00008: val_loss improved from 1.02738 to 0.99943, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.1603 - accuracy: 0.6404 - val_loss: 0.9994 - val_accuracy: 0.6981\n",
            "Epoch 9/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.1122 - accuracy: 0.6514\n",
            "Epoch 00009: val_loss improved from 0.99943 to 0.86854, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.1120 - accuracy: 0.6515 - val_loss: 0.8685 - val_accuracy: 0.7358\n",
            "Epoch 10/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.0721 - accuracy: 0.6624\n",
            "Epoch 00010: val_loss did not improve from 0.86854\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.0725 - accuracy: 0.6623 - val_loss: 0.9411 - val_accuracy: 0.7100\n",
            "Epoch 11/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.6822\n",
            "Epoch 00011: val_loss improved from 0.86854 to 0.84237, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 1.0130 - accuracy: 0.6822 - val_loss: 0.8424 - val_accuracy: 0.7426\n",
            "Epoch 12/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 0.9907 - accuracy: 0.6852\n",
            "Epoch 00012: val_loss improved from 0.84237 to 0.83003, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 86s 9ms/sample - loss: 0.9908 - accuracy: 0.6851 - val_loss: 0.8300 - val_accuracy: 0.7447\n",
            "Epoch 13/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 0.9394 - accuracy: 0.7004\n",
            "Epoch 00013: val_loss improved from 0.83003 to 0.82050, saving model to Model.v_1.hdf5\n",
            "9444/9444 [==============================] - 85s 9ms/sample - loss: 0.9392 - accuracy: 0.7006 - val_loss: 0.8205 - val_accuracy: 0.7502\n",
            "Epoch 14/100\n",
            "9440/9444 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.7086"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwEThfog4WjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the model that performed the best on the validation set\n",
        "model2.load_weights('Model.v_1.hdf5')\n",
        "\n",
        "# Testing the model on the Test data\n",
        "(loss, accuracy) = model2.evaluate(x_test, y_test, batch_size=16, verbose=1)\n",
        "\n",
        "print('Accuracy on test data: {:.2f}%'.format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF6XbgMm7MGZ",
        "colab_type": "text"
      },
      "source": [
        "# Plotting plot :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMj-6gUL7UYB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   **accuracy_plot()** : This function plot graph between train accuracy vs validation/test accuracy\n",
        "2.   **loss_plot():** This function plot graph between train loss vs validation loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpHMjtZGEp_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "def accuracy_plot(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "def loss_plot(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzuVliqNEqBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.mean(history.history['val_accuracy'])\n",
        "std = np.std(history.history['val_accuracy'])\n",
        "\n",
        "accuracy_plot(history)\n",
        "loss_plot(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgNfqbzP8D18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}