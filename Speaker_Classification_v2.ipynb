{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Speaker_Classification_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritikraj660/Speaker-recognition/blob/master/Speaker_Classification_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpNLfJBO1-WH",
        "colab_type": "text"
      },
      "source": [
        "# Installing Packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj01p9v5K199",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjuL4ZnF2F_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RXw9shFmGBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install soundfile\n",
        "#!pip install spafe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhg7V0a2H9L",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jYJat4GEpzL",
        "colab_type": "code",
        "outputId": "0fb837a8-2a1b-441e-bfd1-24061285ee28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import tqdm\n",
        "from scipy.io import wavfile\n",
        "import glob\n",
        "import os,pickle\n",
        "import numpy as np\n",
        "from spafe.features.mfcc import mfcc, imfcc\n",
        "import csv\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import model_from_json\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0XYclYb2NlS",
        "colab_type": "text"
      },
      "source": [
        "# Import Data from Drive :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7LFfT5dOyO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulBEeHGOPVb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFtoL6s2PVFJ",
        "colab_type": "code",
        "outputId": "757073ff-299c-4a07-a7c9-4f51b1756f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1-jhCnWc1Pg5PKjY1aME8JwsVHXljmjFF'\n",
        "fluff, id = link.split('=')\n",
        "print (id) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-jhCnWc1Pg5PKjY1aME8JwsVHXljmjFF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpzvACTgPyj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('LibriSpeech.rar')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCRUyoks2WwX",
        "colab_type": "text"
      },
      "source": [
        "# Extracting Data from (.)rar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUsfP_J5PySI",
        "colab_type": "code",
        "outputId": "f45485b8-f67a-4a9c-9022-6d900a0a6988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip install patool"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffyDpxaCSgDx",
        "colab_type": "code",
        "outputId": "933420a2-5ea2-4120-d1bd-b42392c458f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'adc.json', 'LibriSpeech.rar', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH0Ug5BPShB8",
        "colab_type": "code",
        "outputId": "88ab1faa-f189-4651-fff5-8a44e656f736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"LibriSpeech.rar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting LibriSpeech.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/LibriSpeech.rar\n",
            "patool:     with cwd='./Unpack_4d8vrtuj'\n",
            "patool: ... LibriSpeech.rar extracted to `LibriSpeech'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LibriSpeech'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcQzszcy2htw",
        "colab_type": "text"
      },
      "source": [
        "# Audio Data Preprocessing :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73C5dhr-me2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_(x,mean = False):\n",
        "    if mean == True:\n",
        "        return (x - np.mean(x)) / (np.max(x) - np.min(x)) #normalization                             \n",
        "    else:\n",
        "        return (x-np.mean(x)/np.std(x)) #standardization\n",
        "\n",
        "def zero_handling(x):\n",
        "    \"\"\"\n",
        "    handle the issue with zero values if they are exposed to become an argument\n",
        "    for any log function.\n",
        "\n",
        "    Returns:\n",
        "        vector with zeros substituted with epsilon values.\n",
        "    \"\"\"\n",
        "    return np.where(x == float(0), np.finfo(float).eps, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSPPghULme23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mfcc_(sig,fs):\n",
        "    mfccs  = mfcc(sig, fs=fs, num_ceps=20, pre_emph=1, pre_emph_coeff=0.95, \n",
        "              win_len=0.025, win_hop=0.01, win_type='hamming', nfilts=26, \n",
        "              nfft=512, low_freq=None, high_freq=None, scale='constant', \n",
        "              dct_type=2, use_energy=False, lifter=22)\n",
        "    #print(fs)\n",
        "    return mfccs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaE6275lme26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label(user,total): # its creating lable for splited audio data\n",
        "    k_train = []\n",
        "    for i in range(total):\n",
        "        k_train.append(user)\n",
        "    y_train=np.array(k_train).T\n",
        "    return y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5hyRZYb0njc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "#for file_path in Path('LibriSpeech/test-clean').glob('**/*.flac'):\n",
        "#     print(file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV0iqD15me3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def s2c(mfcc=False,lpcc=False):\n",
        "    x,y=[],[]\n",
        "    data = np.empty([1,148,20])\n",
        "    data_label = np.asarray([])\n",
        "    count =0  # E:\\dataset\\LibriSpeech\\dev-clean\n",
        "    #for file in tqdm(glob.iglob('/LibriSpeech/test-clean//**/*.flac', recursive=True)):\n",
        "    for file in tqdm(Path('LibriSpeech/test-clean').glob('**/*.flac')):\n",
        "        file_name=os.path.basename(file)\n",
        "        user = file_name.split(\"-\")[0]\n",
        "        #print(f)\n",
        "        with soundfile.SoundFile(file) as sound_file:\n",
        "                signal = sound_file.read(dtype=\"float32\")\n",
        "                sr=sound_file.samplerate\n",
        "        signal = norm_(signal,mean = False)\n",
        "        signal = zero_handling(signal)\n",
        "        \n",
        "        if mfcc:\n",
        "            feature = mfcc_(signal,sr)\n",
        "            #print(feature.shape[0])\n",
        "        if lpcc:\n",
        "            feature = lpcc_(signal,sr)   \n",
        "        #if feature.shape[0]>256:\n",
        "        \n",
        "        quotient = int(feature.shape[0]/148)\n",
        "        end_index = feature.shape[0]-(feature.shape[0]%148)\n",
        "        r = feature[0:end_index,:]\n",
        "        re_data = np.reshape(r,(-1,148,20))#b = np.reshape(a, (8, 3, -1))\n",
        "        data=np.concatenate((data,re_data),axis=0)\n",
        "        \n",
        "        re_label = label(user,quotient)\n",
        "        data_label = np.concatenate((data_label,re_label),axis=0)\n",
        "    return data[1:,:,:],data_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atS_es2Ame3Z",
        "colab_type": "code",
        "outputId": "b1aa7885-108d-47ec-b905-e82f26dcfc4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "def write_(x,y):\n",
        "    with open('mfcc_data.csv', 'a') as mfcc_dataFile:\n",
        "        writer = csv.writer(mfcc_dataFile)\n",
        "        writer.writerows(x)\n",
        "    mfcc_dataFile.close()\n",
        "    with open('mfcc_label.csv', 'a') as mfcc_labelFile:\n",
        "        writer = csv.writer(mfcc_labelFile)\n",
        "        writer.writerows(y)\n",
        "    mfcc_labelFile.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 8.82 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAmw3NFOEp8p",
        "colab_type": "code",
        "outputId": "eea67fe8-5a7a-4262-c533-8a395cd8b925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "%%time\n",
        "x,y = s2c(mfcc=True,lpcc=False)\n",
        "\n",
        "#write_(x,y)\n",
        "print(x.shape,y.shape)\n",
        "\n",
        "\n",
        "u = np.unique(y)\n",
        "num_classes = len(u)\n",
        "#print(u)\n",
        "d = dict()\n",
        "for enu,key in enumerate(u,0):\n",
        "    d[key]=enu\n",
        "print(d)\n",
        "for i in range(len(y)):\n",
        "    y[i] = d[y[i]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2620it [03:10,  7.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11806, 148, 20) (11806,)\n",
            "{'1089': 0, '1188': 1, '121': 2, '1221': 3, '1284': 4, '1320': 5, '1580': 6, '1995': 7, '2094': 8, '2300': 9, '237': 10, '260': 11, '2830': 12, '2961': 13, '3570': 14, '3575': 15, '3729': 16, '4077': 17, '4446': 18, '4507': 19, '4970': 20, '4992': 21, '5105': 22, '5142': 23, '5639': 24, '5683': 25, '61': 26, '672': 27, '6829': 28, '6930': 29, '7021': 30, '7127': 31, '7176': 32, '7729': 33, '8224': 34, '8230': 35, '8455': 36, '8463': 37, '8555': 38, '908': 39}\n",
            "CPU times: user 3min 28s, sys: 2min 35s, total: 6min 3s\n",
            "Wall time: 3min 10s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbqqVr_6Ep9d",
        "colab_type": "code",
        "outputId": "b72cca04-d45c-4cae-e5c5-8c4030208b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "X  = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "y_binary = keras.utils.to_categorical(y, num_classes = num_classes)\n",
        "print(y_binary.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y_binary ,test_size=0.20, shuffle= True)\n",
        "\n",
        "print(\"Training shape: {0}, Training label shape : {1}\".format(x_train.shape,y_train.shape))\n",
        "print(\"Training shape: {0}, Training label shape : {1}\".format(x_test.shape,y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11806, 148, 20, 1)\n",
            "(11806, 40)\n",
            "Training shape: (9444, 148, 20, 1), Training label shape : (9444, 40)\n",
            "Training shape: (2362, 148, 20, 1), Training label shape : (2362, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1HwaUks6gKY",
        "colab_type": "text"
      },
      "source": [
        "# Creating CNN Architecture :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6w-KrxMEp-O",
        "colab_type": "code",
        "outputId": "78fe6f88-37a1-4b88-be20-b8f34d877312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.python.keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model2 = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x.shape[1],x.shape[2],1)))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(40, activation='softmax'))\n",
        "\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model2.summary())#Train and Test The Model\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 146, 18, 32)       320       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 144, 16, 32)       9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 70, 6, 64)         18496     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 68, 4, 64)         36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               1114368   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 40)                10280     \n",
            "=================================================================\n",
            "Total params: 1,189,640\n",
            "Trainable params: 1,189,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EulSDA-nS7lu",
        "colab_type": "code",
        "outputId": "99fa78a9-1aca-48dd-bbd3-0470edea61f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow.python.keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x.shape[1],x.shape[2],1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(40, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 146, 18, 32)       320       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 144, 16, 32)       9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 72, 8, 32)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 72, 8, 32)         128       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 70, 6, 64)         18496     \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 68, 4, 64)         36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 34, 2, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4352)              17408     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               1114368   \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 40)                2600      \n",
            "=================================================================\n",
            "Total params: 1,242,184\n",
            "Trainable params: 1,232,648\n",
            "Non-trainable params: 9,536\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C4e0DA7Ep_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0e9a4d11-2b3f-4072-9de9-18a1d6d6920e"
      },
      "source": [
        "%%time\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# Saving the model that performed the best on the validation set\n",
        "checkpoint = ModelCheckpoint(filepath='Model.v_2.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "# Training the model for 40 epochs\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=200, \n",
        "                    validation_data=(x_test, y_test), verbose=0, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00099: val_loss did not improve from 0.92646\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.92646\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.92646\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.92646\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.92646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwEThfog4WjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the model that performed the best on the validation set\n",
        "model2.load_weights('Model.v_2.hdf5')\n",
        "\n",
        "# Testing the model on the Test data\n",
        "(loss, accuracy) = model.evaluate(x_test, y_test, batch_size=32, verbose=1)\n",
        "\n",
        "print('Accuracy on test data: {:.2f}%'.format(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF6XbgMm7MGZ",
        "colab_type": "text"
      },
      "source": [
        "# Plotting plot :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMj-6gUL7UYB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   **accuracy_plot()** : This function plot graph between train accuracy vs validation/test accuracy\n",
        "2.   **loss_plot():** This function plot graph between train loss vs validation loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpHMjtZGEp_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "def accuracy_plot(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "def loss_plot(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzuVliqNEqBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.mean(history.history['val_accuracy'])\n",
        "std = np.std(history.history['val_accuracy'])\n",
        "\n",
        "accuracy_plot(history)\n",
        "loss_plot(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgNfqbzP8D18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}